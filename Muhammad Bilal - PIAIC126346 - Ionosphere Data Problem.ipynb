{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thirty-testing",
   "metadata": {},
   "source": [
    "# Muhammad Bilal - PIAIC126346 - Ionosphere Data Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "front-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "searching-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ionosphere_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "educated-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chubby-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1       int64\n",
       "feature2       int64\n",
       "feature3     float64\n",
       "feature4     float64\n",
       "feature5     float64\n",
       "feature6     float64\n",
       "feature7     float64\n",
       "feature8     float64\n",
       "feature9     float64\n",
       "feature10    float64\n",
       "feature11    float64\n",
       "feature12    float64\n",
       "feature13    float64\n",
       "feature14    float64\n",
       "feature15    float64\n",
       "feature16    float64\n",
       "feature17    float64\n",
       "feature18    float64\n",
       "feature19    float64\n",
       "feature20    float64\n",
       "feature21    float64\n",
       "feature22    float64\n",
       "feature23    float64\n",
       "feature24    float64\n",
       "feature25    float64\n",
       "feature26    float64\n",
       "feature27    float64\n",
       "feature28    float64\n",
       "feature29    float64\n",
       "feature30    float64\n",
       "feature31    float64\n",
       "feature32    float64\n",
       "feature33    float64\n",
       "feature34    float64\n",
       "label         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "danish-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature2   351 non-null    int64  \n",
      " 2   feature3   351 non-null    float64\n",
      " 3   feature4   351 non-null    float64\n",
      " 4   feature5   351 non-null    float64\n",
      " 5   feature6   351 non-null    float64\n",
      " 6   feature7   351 non-null    float64\n",
      " 7   feature8   351 non-null    float64\n",
      " 8   feature9   351 non-null    float64\n",
      " 9   feature10  351 non-null    float64\n",
      " 10  feature11  351 non-null    float64\n",
      " 11  feature12  351 non-null    float64\n",
      " 12  feature13  351 non-null    float64\n",
      " 13  feature14  351 non-null    float64\n",
      " 14  feature15  351 non-null    float64\n",
      " 15  feature16  351 non-null    float64\n",
      " 16  feature17  351 non-null    float64\n",
      " 17  feature18  351 non-null    float64\n",
      " 18  feature19  351 non-null    float64\n",
      " 19  feature20  351 non-null    float64\n",
      " 20  feature21  351 non-null    float64\n",
      " 21  feature22  351 non-null    float64\n",
      " 22  feature23  351 non-null    float64\n",
      " 23  feature24  351 non-null    float64\n",
      " 24  feature25  351 non-null    float64\n",
      " 25  feature26  351 non-null    float64\n",
      " 26  feature27  351 non-null    float64\n",
      " 27  feature28  351 non-null    float64\n",
      " 28  feature29  351 non-null    float64\n",
      " 29  feature30  351 non-null    float64\n",
      " 30  feature31  351 non-null    float64\n",
      " 31  feature32  351 non-null    float64\n",
      " 32  feature33  351 non-null    float64\n",
      " 33  feature34  351 non-null    float64\n",
      " 34  label      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lonely-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1     0\n",
      "feature2     0\n",
      "feature3     0\n",
      "feature4     0\n",
      "feature5     0\n",
      "feature6     0\n",
      "feature7     0\n",
      "feature8     0\n",
      "feature9     0\n",
      "feature10    0\n",
      "feature11    0\n",
      "feature12    0\n",
      "feature13    0\n",
      "feature14    0\n",
      "feature15    0\n",
      "feature16    0\n",
      "feature17    0\n",
      "feature18    0\n",
      "feature19    0\n",
      "feature20    0\n",
      "feature21    0\n",
      "feature22    0\n",
      "feature23    0\n",
      "feature24    0\n",
      "feature25    0\n",
      "feature26    0\n",
      "feature27    0\n",
      "feature28    0\n",
      "feature29    0\n",
      "feature30    0\n",
      "feature31    0\n",
      "feature32    0\n",
      "feature33    0\n",
      "feature34    0\n",
      "label        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "macro-combine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0           1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1           1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2           1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3           1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4           1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "346         1         0   0.83508   0.08298   0.73739  -0.14706   0.84349   \n",
       "347         1         0   0.95113   0.00419   0.95183  -0.02723   0.93438   \n",
       "348         1         0   0.94701  -0.00034   0.93207  -0.03227   0.95177   \n",
       "349         1         0   0.90608  -0.01657   0.98122  -0.01989   0.95691   \n",
       "350         1         0   0.84710   0.13533   0.73638  -0.06151   0.87873   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0    -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1    -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2    -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3    -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4    -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "..        ...       ...        ...  ...        ...        ...        ...   \n",
       "346  -0.05567   0.90441   -0.04622  ...   -0.04202    0.83479    0.00123   \n",
       "347  -0.01920   0.94590    0.01606  ...    0.01361    0.93522    0.04925   \n",
       "348  -0.03431   0.95584    0.02446  ...    0.03193    0.92489    0.02542   \n",
       "349  -0.03646   0.85746    0.00110  ...   -0.02099    0.89147   -0.07760   \n",
       "350   0.08260   0.88928   -0.09139  ...   -0.15114    0.81147   -0.04822   \n",
       "\n",
       "     feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0      0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1     -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2      0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3      1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4      0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "346    1.00000    0.12815    0.86660   -0.10714    0.90546   -0.04307      g  \n",
       "347    0.93159    0.08168    0.94066   -0.00035    0.91483    0.04712      g  \n",
       "348    0.92120    0.02242    0.92459    0.00442    0.92697   -0.00577      g  \n",
       "349    0.82983   -0.17238    0.96022   -0.03757    0.87403   -0.16243      g  \n",
       "350    0.78207   -0.00703    0.75747   -0.06678    0.85764   -0.06151      g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "secondary-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)\n",
    "data.reset_index(inplace=True, drop=True)             #Data did not need to be shuffled but I saw there was a pattern in \n",
    "                                                      #labels repitition so I shuffled the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stopped-ecuador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.16195</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05558</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.22978</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.06823</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08299</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14194</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.07439</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74916</td>\n",
       "      <td>0.02549</td>\n",
       "      <td>0.98994</td>\n",
       "      <td>0.09792</td>\n",
       "      <td>0.75855</td>\n",
       "      <td>0.12877</td>\n",
       "      <td>0.74313</td>\n",
       "      <td>-0.09188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01207</td>\n",
       "      <td>0.82271</td>\n",
       "      <td>0.02552</td>\n",
       "      <td>0.72435</td>\n",
       "      <td>-0.01073</td>\n",
       "      <td>0.90409</td>\n",
       "      <td>0.11066</td>\n",
       "      <td>0.72837</td>\n",
       "      <td>0.02750</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03730</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.07383</td>\n",
       "      <td>0.99601</td>\n",
       "      <td>-0.11039</td>\n",
       "      <td>0.99838</td>\n",
       "      <td>-0.09931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42990</td>\n",
       "      <td>0.83172</td>\n",
       "      <td>-0.43122</td>\n",
       "      <td>0.81433</td>\n",
       "      <td>-0.42593</td>\n",
       "      <td>0.77919</td>\n",
       "      <td>-0.47977</td>\n",
       "      <td>0.75115</td>\n",
       "      <td>-0.50152</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87111</td>\n",
       "      <td>0.04326</td>\n",
       "      <td>0.79946</td>\n",
       "      <td>0.18297</td>\n",
       "      <td>0.99009</td>\n",
       "      <td>0.29292</td>\n",
       "      <td>0.89455</td>\n",
       "      <td>-0.08337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09193</td>\n",
       "      <td>0.85967</td>\n",
       "      <td>-0.02908</td>\n",
       "      <td>0.78774</td>\n",
       "      <td>-0.04101</td>\n",
       "      <td>0.75935</td>\n",
       "      <td>0.21812</td>\n",
       "      <td>0.88238</td>\n",
       "      <td>0.09193</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99645</td>\n",
       "      <td>0.06468</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.01236</td>\n",
       "      <td>0.97811</td>\n",
       "      <td>0.02498</td>\n",
       "      <td>0.96112</td>\n",
       "      <td>0.02312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13412</td>\n",
       "      <td>0.79476</td>\n",
       "      <td>0.13638</td>\n",
       "      <td>0.79110</td>\n",
       "      <td>0.15379</td>\n",
       "      <td>0.77122</td>\n",
       "      <td>0.15930</td>\n",
       "      <td>0.70941</td>\n",
       "      <td>0.12015</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65845</td>\n",
       "      <td>0.43617</td>\n",
       "      <td>0.44681</td>\n",
       "      <td>0.74804</td>\n",
       "      <td>0.05319</td>\n",
       "      <td>0.85106</td>\n",
       "      <td>-0.32027</td>\n",
       "      <td>0.82139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18645</td>\n",
       "      <td>0.74758</td>\n",
       "      <td>0.23713</td>\n",
       "      <td>0.45185</td>\n",
       "      <td>0.59071</td>\n",
       "      <td>0.20549</td>\n",
       "      <td>0.76764</td>\n",
       "      <td>-0.18533</td>\n",
       "      <td>0.74356</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05866</td>\n",
       "      <td>-0.00838</td>\n",
       "      <td>0.06704</td>\n",
       "      <td>0.00838</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.01117</td>\n",
       "      <td>0.00559</td>\n",
       "      <td>-0.03911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00559</td>\n",
       "      <td>0.10335</td>\n",
       "      <td>-0.00838</td>\n",
       "      <td>0.03073</td>\n",
       "      <td>-0.00279</td>\n",
       "      <td>0.04469</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04749</td>\n",
       "      <td>-0.03352</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>-0.25000</td>\n",
       "      <td>0.44444</td>\n",
       "      <td>0.22222</td>\n",
       "      <td>0.38889</td>\n",
       "      <td>0.16667</td>\n",
       "      <td>0.41667</td>\n",
       "      <td>0.13889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.41543</td>\n",
       "      <td>-0.14256</td>\n",
       "      <td>0.19444</td>\n",
       "      <td>-0.13889</td>\n",
       "      <td>0.36924</td>\n",
       "      <td>-0.14809</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>-0.50000</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0           1         0   1.00000   0.16195   1.00000  -0.05558   1.00000   \n",
       "1           1         0   0.74916   0.02549   0.98994   0.09792   0.75855   \n",
       "2           0         0   1.00000  -1.00000   1.00000   1.00000   1.00000   \n",
       "3           1         0   1.00000  -0.03730   1.00000  -0.07383   0.99601   \n",
       "4           1         0   0.87111   0.04326   0.79946   0.18297   0.99009   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "346         1         0   0.99645   0.06468   1.00000  -0.01236   0.97811   \n",
       "347         0         0   1.00000   1.00000  -1.00000  -1.00000  -1.00000   \n",
       "348         1         0   0.65845   0.43617   0.44681   0.74804   0.05319   \n",
       "349         1         0   0.05866  -0.00838   0.06704   0.00838   0.00000   \n",
       "350         1         0   0.33333  -0.25000   0.44444   0.22222   0.38889   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0     0.01373   1.00000   -0.12352  ...   -0.22978    1.00000   -0.06823   \n",
       "1     0.12877   0.74313   -0.09188  ...   -0.01207    0.82271    0.02552   \n",
       "2    -1.00000   1.00000    1.00000  ...   -1.00000    1.00000   -1.00000   \n",
       "3    -0.11039   0.99838   -0.09931  ...   -0.42990    0.83172   -0.43122   \n",
       "4     0.29292   0.89455   -0.08337  ...   -0.09193    0.85967   -0.02908   \n",
       "..        ...       ...        ...  ...        ...        ...        ...   \n",
       "346   0.02498   0.96112    0.02312  ...    0.13412    0.79476    0.13638   \n",
       "347  -1.00000   0.00000    0.00000  ...    0.00000    1.00000   -1.00000   \n",
       "348   0.85106  -0.32027    0.82139  ...   -0.18645    0.74758    0.23713   \n",
       "349  -0.01117   0.00559   -0.03911  ...    0.00559    0.10335   -0.00838   \n",
       "350   0.16667   0.41667    0.13889  ...    0.08333    0.41543   -0.14256   \n",
       "\n",
       "     feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0      1.00000    0.08299    1.00000   -0.14194    1.00000   -0.07439      g  \n",
       "1      0.72435   -0.01073    0.90409    0.11066    0.72837    0.02750      g  \n",
       "2      1.00000    1.00000    1.00000   -1.00000    1.00000    1.00000      b  \n",
       "3      0.81433   -0.42593    0.77919   -0.47977    0.75115   -0.50152      g  \n",
       "4      0.78774   -0.04101    0.75935    0.21812    0.88238    0.09193      g  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "346    0.79110    0.15379    0.77122    0.15930    0.70941    0.12015      g  \n",
       "347    0.00000    0.00000   -1.00000   -1.00000   -1.00000   -1.00000      b  \n",
       "348    0.45185    0.59071    0.20549    0.76764   -0.18533    0.74356      g  \n",
       "349    0.03073   -0.00279    0.04469    0.00000    0.04749   -0.03352      b  \n",
       "350    0.19444   -0.13889    0.36924   -0.14809    0.08333   -0.50000      g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "written-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "data['label'] = lb.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thrown-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(labels = 'label', axis = 1)\n",
    "y = data[['label']]                                #Encoding labels : 1 for Good and 0 for Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "japanese-terminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        1\n",
       "..     ...\n",
       "346      1\n",
       "347      0\n",
       "348      1\n",
       "349      0\n",
       "350      1\n",
       "\n",
       "[351 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "equal-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1       int64\n",
       "feature2       int64\n",
       "feature3     float64\n",
       "feature4     float64\n",
       "feature5     float64\n",
       "feature6     float64\n",
       "feature7     float64\n",
       "feature8     float64\n",
       "feature9     float64\n",
       "feature10    float64\n",
       "feature11    float64\n",
       "feature12    float64\n",
       "feature13    float64\n",
       "feature14    float64\n",
       "feature15    float64\n",
       "feature16    float64\n",
       "feature17    float64\n",
       "feature18    float64\n",
       "feature19    float64\n",
       "feature20    float64\n",
       "feature21    float64\n",
       "feature22    float64\n",
       "feature23    float64\n",
       "feature24    float64\n",
       "feature25    float64\n",
       "feature26    float64\n",
       "feature27    float64\n",
       "feature28    float64\n",
       "feature29    float64\n",
       "feature30    float64\n",
       "feature31    float64\n",
       "feature32    float64\n",
       "feature33    float64\n",
       "feature34    float64\n",
       "label          int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faced-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data , train_labels , test_labels = train_test_split(x, y, train_size = 0.6 , test_size = 0.4 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regular-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train_data = sc.fit_transform(train_data)         #Standarized the input data\n",
    "test_data = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "white-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape = (train_data.shape[1], )))\n",
    "model.add(layers.Dense(8, activation='relu'))          #Added one more hidden layer and my test accuracy got better > 92%\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "amateur-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sitting-introduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8159 - accuracy: 0.3810\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.4476\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6381\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7238\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7619\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8238\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8381\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.8524\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8714\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8857\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8810\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8952\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8905\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8905\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.9048\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.9048\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.9048\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9143\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.9048\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.9143\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9143\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.9190\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9143\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9190\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9190\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9238\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9238\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9238\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9381\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1905 - accuracy: 0.9429\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9476\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9524\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9476\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9524\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9571\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9571\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9619\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9619\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9619\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9619\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9619\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9667\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9667\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9667\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9714\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9714\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9714\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9762\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9762\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9762\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9762\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9762\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9762\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9762\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9762\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9762\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9762\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9762\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9762\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9810\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.96 - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9810\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9905\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9905\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9952\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9905\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9905\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9905\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9952\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9905\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9905\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9952\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9952\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9952\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9952\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9952\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9952\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9952\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9952\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9952\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9952\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9952\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9952\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9952\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9952\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9952\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9952\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9952\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9952\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9952\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9952\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9952\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9952\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9952\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "Result = model.fit(train_data, train_labels, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "broken-grade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = Result.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "alert-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_values = history_dict['loss']\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "individual-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.9220\n",
      "[0.36075955629348755, 0.9219858050346375]\n"
     ]
    }
   ],
   "source": [
    "Evaluation = model.evaluate(test_data, test_labels)\n",
    "print(Evaluation)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "distant-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "smart-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9837160e-01]\n",
      " [1.0587213e-08]\n",
      " [9.9357718e-01]\n",
      " [9.9939907e-01]\n",
      " [9.3787408e-01]\n",
      " [9.9973905e-01]\n",
      " [9.9983221e-01]\n",
      " [9.9979717e-01]\n",
      " [3.1910449e-01]\n",
      " [9.9979770e-01]\n",
      " [1.1220658e-01]\n",
      " [8.0882442e-01]\n",
      " [3.1447613e-01]\n",
      " [9.9569309e-01]\n",
      " [9.9835122e-01]\n",
      " [9.9934196e-01]\n",
      " [9.9971211e-01]\n",
      " [5.3837001e-03]\n",
      " [1.3415161e-01]\n",
      " [9.9212086e-01]\n",
      " [9.9985957e-01]\n",
      " [2.6995496e-13]\n",
      " [9.8457146e-01]\n",
      " [9.9291241e-01]\n",
      " [4.5372875e-07]\n",
      " [9.9516803e-01]\n",
      " [9.9703002e-01]\n",
      " [9.8068249e-01]\n",
      " [9.9951142e-01]\n",
      " [9.6544191e-08]\n",
      " [9.8971152e-01]\n",
      " [9.9717778e-01]\n",
      " [9.9987113e-01]\n",
      " [9.8519784e-01]\n",
      " [6.3366571e-08]\n",
      " [9.7381294e-01]\n",
      " [9.9959600e-01]\n",
      " [9.8833239e-01]\n",
      " [9.9722469e-01]\n",
      " [9.5852029e-01]\n",
      " [3.9223075e-02]\n",
      " [9.8457134e-01]\n",
      " [9.9911332e-01]\n",
      " [1.8841028e-04]\n",
      " [9.9718738e-01]\n",
      " [9.9872154e-01]\n",
      " [9.9990559e-01]\n",
      " [9.9986279e-01]\n",
      " [7.8234076e-04]\n",
      " [2.4981049e-05]\n",
      " [9.9555838e-01]\n",
      " [9.8206961e-01]\n",
      " [2.3503512e-02]\n",
      " [9.9981022e-01]\n",
      " [9.9985886e-01]\n",
      " [9.9544680e-01]\n",
      " [9.8827088e-01]\n",
      " [9.8509234e-01]\n",
      " [9.9409437e-01]\n",
      " [4.4150725e-01]\n",
      " [9.9880636e-01]\n",
      " [9.9962693e-01]\n",
      " [1.3592839e-04]\n",
      " [1.3504446e-02]\n",
      " [9.9932587e-01]\n",
      " [9.9621660e-01]\n",
      " [8.8691270e-01]\n",
      " [9.9645364e-01]\n",
      " [9.9918890e-01]\n",
      " [9.9641144e-01]\n",
      " [9.9844271e-01]\n",
      " [2.7283956e-11]\n",
      " [9.8807681e-01]\n",
      " [9.9975765e-01]\n",
      " [9.9981302e-01]\n",
      " [9.9981189e-01]\n",
      " [7.8091797e-11]\n",
      " [9.9993455e-01]\n",
      " [9.9859911e-01]\n",
      " [1.6679695e-01]\n",
      " [9.9981540e-01]\n",
      " [9.9376237e-01]\n",
      " [9.9139965e-01]\n",
      " [9.9793655e-01]\n",
      " [8.7895465e-01]\n",
      " [9.9946308e-01]\n",
      " [7.5548563e-14]\n",
      " [9.9413991e-03]\n",
      " [9.9738801e-01]\n",
      " [9.9674475e-01]\n",
      " [6.2628114e-01]\n",
      " [9.9681735e-01]\n",
      " [9.9864274e-01]\n",
      " [7.7184814e-01]\n",
      " [1.3911401e-08]\n",
      " [9.9259996e-01]\n",
      " [8.6475205e-01]\n",
      " [1.9007408e-05]\n",
      " [9.9949670e-01]\n",
      " [4.7475117e-01]\n",
      " [9.9936378e-01]\n",
      " [9.9959576e-01]\n",
      " [8.1199706e-03]\n",
      " [5.7288215e-08]\n",
      " [9.8508722e-01]\n",
      " [9.9931008e-01]\n",
      " [9.5812607e-01]\n",
      " [9.9978042e-01]\n",
      " [9.0759349e-01]\n",
      " [9.3475902e-01]\n",
      " [9.9962825e-01]\n",
      " [9.9974430e-01]\n",
      " [4.2185992e-02]\n",
      " [9.7833943e-01]\n",
      " [1.6844779e-02]\n",
      " [3.5018975e-01]\n",
      " [9.8118407e-01]\n",
      " [9.6644861e-01]\n",
      " [8.2593099e-12]\n",
      " [1.0914181e-09]\n",
      " [9.9916053e-01]\n",
      " [9.9935609e-01]\n",
      " [4.2569518e-05]\n",
      " [1.1507194e-06]\n",
      " [9.9049342e-01]\n",
      " [9.9290812e-01]\n",
      " [6.4346866e-09]\n",
      " [9.9826610e-01]\n",
      " [4.2537444e-15]\n",
      " [9.9903488e-01]\n",
      " [9.9496722e-01]\n",
      " [9.9931127e-01]\n",
      " [1.8146785e-09]\n",
      " [9.9970323e-01]\n",
      " [3.3179296e-11]\n",
      " [9.7607094e-01]\n",
      " [9.9625498e-01]\n",
      " [3.1181642e-09]\n",
      " [9.9920636e-01]\n",
      " [9.9859273e-01]\n",
      " [9.9741751e-01]]\n",
      "(141, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Prediction)\n",
    "print(Prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "monthly-supervisor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Shape :  (141, 1)  Original Shape :  (141, 1)\n",
      "----------------------------------------------------------------\n",
      "Predicted Labels\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "----------------------------------------------------------------\n",
      "Original Labels\n",
      "      label\n",
      "157      1\n",
      "342      0\n",
      "316      1\n",
      "234      1\n",
      "155      0\n",
      "..     ...\n",
      "172      1\n",
      "175      0\n",
      "232      1\n",
      "340      1\n",
      "92       1\n",
      "\n",
      "[141 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "a = np.where(Prediction < 0.5 , 0 , 1)\n",
    "print(\"Predicted Shape : \",a.shape, \" Original Shape : \", test_labels.shape)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Predicted Labels\\n\", a)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Original Labels\\n\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "understood-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Bad']\n",
      " ['Good']\n",
      " ['Good']\n",
      " ['Good']]\n",
      "-------------------------------------\n",
      "[['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Not Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']\n",
      " ['Match']]\n",
      "Prediction match with original labels for :                    130\n",
      "Prediction does not match with original labels for :           11\n"
     ]
    }
   ],
   "source": [
    "b = np.where(a == 1, 'Good', 'Bad')\n",
    "print(b)\n",
    "c = np.where (a == test_labels , 'Match' , 'Not Match')\n",
    "print(\"-------------------------------------\")\n",
    "print(c)\n",
    "print(\"Prediction match with original labels for :                   \",  len(c[c == 'Match']))\n",
    "print(\"Prediction does not match with original labels for :          \", len(c[c == 'Not Match']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bored-hamburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Percentage :  92.19858156028369\n"
     ]
    }
   ],
   "source": [
    "Prediction_Percentage = (len(c[c == 'Match'])/test_labels.shape[0])*100\n",
    "print(\"Prediction Percentage : \", Prediction_Percentage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
